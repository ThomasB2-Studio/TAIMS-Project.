import streamlit as st
import os
from dotenv import load_dotenv
import google.generativeai as genai

# --- 1. Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="TAIMS", page_icon="ğŸ¯", layout="wide")

# --- 2. Káº¾T Ná»I & KIá»‚M TRA MODEL ---
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")

st.title("TAIMS ğŸ¯ - PhiÃªn báº£n Sá»­a Lá»—i")

# Kiá»ƒm tra Key
if not api_key:
    st.error("âŒ ChÆ°a tÃ¬m tháº¥y API Key trong file .env")
    st.stop()

# Cáº¥u hÃ¬nh AI
try:
    genai.configure(api_key=api_key)
except Exception as e:
    st.error(f"âŒ Lá»—i cáº¥u hÃ¬nh Key: {e}")
    st.stop()

# --- 3. Tá»° Äá»˜NG TÃŒM MODEL (DEBUG) ---
# Pháº§n nÃ y giÃºp Thomas biáº¿t chÃ­nh xÃ¡c Key cá»§a mÃ¬nh dÃ¹ng Ä‘Æ°á»£c model nÃ o
with st.sidebar:
    st.header("ğŸ”§ ThÃ´ng tin Ká»¹ thuáº­t")
    st.write("Äang kiá»ƒm tra cÃ¡c Model kháº£ dá»¥ng...")
    try:
        available_models = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                available_models.append(m.name)

        if available_models:
            st.success(f"TÃ¬m tháº¥y {len(available_models)} model!")
            # Cho phÃ©p chá»n model Ä‘á»ƒ trÃ¡nh lá»—i 404
            selected_model = st.selectbox("Chá»n Model:", available_models, index=0)
        else:
            st.error("KhÃ´ng tÃ¬m tháº¥y Model nÃ o há»— trá»£ táº¡o ná»™i dung.")
            st.stop()

    except Exception as e:
        st.error(f"Lá»—i khi liá»‡t kÃª model: {e}")
        selected_model = "models/gemini-1.5-flash"  # Fallback

# --- 4. KHá»I Táº O Bá»˜ NHá»š (SESSION STATE) ---
# ÄÃ¢y lÃ  Ä‘oáº¡n báº¡n Ä‘Ã£ phÃ¡t hiá»‡n lá»—i, tÃ´i Ä‘Ã£ sá»­a láº¡i Ä‘Ãºng cÃº phÃ¡p
if "tasks" not in st.session_state:
    st.session_state.tasks = []  # âœ… ÄÃƒ Sá»¬A: GÃ¡n báº±ng danh sÃ¡ch rá»—ng

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- 5. GIAO DIá»†N CHÃNH ---
st.caption(f"Äang sá»­ dá»¥ng bá»™ nÃ£o: `{selected_model}`")

# Hiá»ƒn thá»‹ lá»‹ch sá»­ chat
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Ã” nháº­p liá»‡u
user_input = st.chat_input("Nháº­p má»¥c tiÃªu cá»§a báº¡n (VÃ­ dá»¥: Há»c tiáº¿ng PhÃ¡p trong 2 thÃ¡ng)...")

if user_input:
    # 1. Hiá»‡n cÃ¢u há»i cá»§a user
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # 2. AI xá»­ lÃ½
    with st.chat_message("assistant"):
        with st.spinner("Thomas Ä‘á»£i chÃºt, AI Ä‘ang suy nghÄ©..."):
            try:
                # Khá»Ÿi táº¡o model tá»« cÃ¡i tÃªn Ä‘Ã£ chá»n á»Ÿ Sidebar
                model = genai.GenerativeModel(selected_model)

                # Gá»­i lá»‡nh
                response = model.generate_content(
                    f"HÃ£y Ä‘Ã³ng vai trá»£ lÃ½ TAIMS. GiÃºp tÃ´i chia nhá» má»¥c tiÃªu nÃ y thÃ nh 3 bÆ°á»›c cá»¥ thá»ƒ kÃ¨m thá»i gian: {user_input}")
                ai_reply = response.text

                # Hiá»‡n cÃ¢u tráº£ lá»i
                st.markdown(ai_reply)

                # LÆ°u vÃ o lá»‹ch sá»­
                st.session_state.chat_history.append({"role": "assistant", "content": ai_reply})

                # (Táº¡m thá»i giáº£ láº­p tasks Ä‘á»ƒ test lá»—i session_state)
                st.session_state.tasks = ["ÄÃ£ nháº­n káº¿ hoáº¡ch tá»« AI"]

            except Exception as e:
                st.error(f"âŒ Váº«n cÃ²n lá»—i: {e}")
                st.info("Máº¹o: HÃ£y thá»­ chá»n Model khÃ¡c á»Ÿ thanh bÃªn trÃ¡i (Sidebar)!")